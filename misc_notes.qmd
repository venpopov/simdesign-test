---
title: "Notes on SimDesign"
toc: true
execute: 
  freeze: true
---

Gidon really likes the package so let's give this a shot.

## Working with the SimDesign Package

```{r setup}
library(SimDesign)
```

### Step 1: Generate a structural template for a generate-analyse-summarise workflow

The first recommendation in the tutorial is to use 

```r
SimDesign::SimFunctions()
```

to generate a template. Let's save it to a file:

```r
SimDesign::SimFunctions(file = "R/getting_started.R")
```

Note: this create a double `.R` extension. The package does not check if you already have an extension in the file name (so don't add `.R` to the file name):

```r
SimDesign::SimFunctions(file = "R/getting_started")
```

The output looks like this:

```{.r filename="R/getting_started.R"}
library(SimDesign)

Design <- createDesign(factor1 = NA,
                       factor2 = NA)

#-------------------------------------------------------------------

Generate <- function(condition, fixed_objects) {
    dat <- data.frame()
    dat
}

Analyse <- function(condition, dat, fixed_objects) {
    ret <- nc(stat1 = NaN, stat2 = NaN)
    ret
}

Summarise <- function(condition, results, fixed_objects) {
    ret <- c(bias = NaN, RMSE = NaN)
    ret
}

#-------------------------------------------------------------------

res <- runSimulation(design=Design, replications=2, generate=Generate, 
                     analyse=Analyse, summarise=Summarise)
res

```

I am not a big fan of the capital letters in the function names but I'll deal with that later.

### Step 2: Use `createDesign()` to create a design object

I'm not absolutely sure what a design is in this context, but it sounds like it might be a grid of parameters? The tutorial recommends using the following function and then editing the resulting Design object definition:

```r
createDesign()
```

I see that this is already present in the `getting_started.R` file. 

This looks just like an `expand.grid` wrapped in a tible:

```{r toy_design}
Design <- createDesign(a = c(1,2,5), b = c(2,5))
Design
```

The only difference seems to be the presence of an extra attribute `Design.ID` and that this object is of class `Design`. Is any of this necesary? I will setup a basic grid for testing the simple 2-parameter mixture model:

```{r play_design}
Design <- createDesign(n = c(20, 50, 100),
                       pmem = c(0.3, 0.6, 0.9),
                       kappa = c(2, 8, 32))
```

### Step 3: Edit the `Generate`, `Analyse`, and `Summarise` functions

I replaced them with functions for generating data from the 2-parameter mixture model, fitting the model via mixtur, and summarizing the correlation between the true and estimated parameters:

```{r first_attempt_at_SimDesign}
#| error: true
library(SimDesign)
library(bmm)
library(mixtur)

Design <- createDesign(
  n = c(20, 50, 100),
  pmem = c(0.3, 0.6, 0.9),
  kappa = c(2, 8, 32)
)

#-------------------------------------------------------------------

Generate <- function(condition, fixed_objects) {
  reponse <- bmm::rmixture2p(
    n = condition$n,
    kappa = condition$kappa,
    p_mem = condition$pmem
  )
  data.frame(response = reponse, target = 0, id = 1)
}

Analyse <- function(condition, dat, fixed_objects) {
  suppressMessages(
    mixtur::fit_mixtur(dat, model = "2_component", unit = "radians") |>
      dplyr::select(kappa, p_t) |>
      dplyr::rename(kappa_est = kappa, pmem_est = p_t)
  )
}

Summarise <- function(condition, results, fixed_objects) {
  list(
    corr = list(
      kappa = cor(condition$kappa, results$kappa_est),
      pmem = cor(condition$pmem, results$pmem_est)
    ),
    bias = list(
      kappa = mean(results$kappa_est - condition$kappa),
      pmem = mean(results$pmem_est - condition$pmem)
    ),
    rmse = list(
      kappa = sqrt(mean((results$kappa_est - condition$kappa)^2)),
      pmem = sqrt(mean((results$pmem_est - condition$pmem)^2))
    )
  )
}

#-------------------------------------------------------------------

try({
  res <- runSimulation(
    design = Design, replications = 4, generate = Generate,
    analyse = Analyse, summarise = Summarise
  )
})
```

which... gives me an error.

I have misunderstood whne the Summarise function is applied. I thought it is used on the final results over the entire design grid. But the real workflow is like this:

![](assets/simdesign-structure.png)

Specifically, for a single row of the design grid, we get as many results from Analyze() as there are replications. Then Summarise() is applied to these results. This means that the `condition` object in Summarise() is a single row of the design grid, and I cannot compute the correlation between the true and estimated parameters as I did. I will need to do that **outside** of the runSimulation() call.

### Interlude: Figure out the format of the arguments passed to Summarise

I don't quite understand what the format of the variables passed to Summarise is. I added the following two lines to the `Summarise` function:

```{r Summarise_debug}
Summarise <- function(condition, results, fixed_objects) {
  saveRDS(results, "output/results.rds")
  saveRDS(condition, "output/condition.rds")
  list(
    bias = list(
      kappa = mean(results$kappa_est - condition$kappa),
      pmem = mean(results$pmem_est - condition$pmem)
    ),
    rmse = list(
      kappa = sqrt(mean((results$kappa_est - condition$kappa)^2)),
      pmem = sqrt(mean((results$pmem_est - condition$pmem)^2))
    )
  )
}
res <- runSimulation(
  design = Design, replications = 4, generate = Generate,
  analyse = Analyse, summarise = Summarise, verbose = FALSE
)
```

after running the script, I can inspect the files:

```{r inspect_condition}
readRDS('output/condition.rds')
```

Thus the condition input is a tibble with a single row of the Design object (plus an extra variable ID). 

Now the results object. I wasn't sure what to expect, because the Analyse functio returns a data.frame with one row. Was I going to get a list of data.frames? Or a data.frame with multiple rows? 

```{r inspect_results}
readRDS('output/results.rds') |> str()
```

A data.frame with multiple rows it is. 

What happens if I return a list from Analyse() instead of a data.frame?

```{r Analyse_list}
Analyse <- function(condition, dat, fixed_objects) {
  suppressMessages(
    mixtur::fit_mixtur(dat, model = "2_component", unit = "radians") |>
      dplyr::select(kappa, p_t) |>
      dplyr::rename(kappa_est = kappa, pmem_est = p_t)
  ) |> as.list()
} 

res <- runSimulation(
  design = Design, replications = 4, generate = Generate,
  analyse = Analyse, summarise = Summarise, verbose = FALSE
)

readRDS('output/results.rds') |> str()
```

A cool, it forces the result to be of the same form as the output of Analyze. This is important and I should remember this.

```{r analyze_df}
#| echo: false
Analyse <- function(condition, dat, fixed_objects) {
  suppressMessages(
    mixtur::fit_mixtur(dat, model = "2_component", unit = "radians") |>
      dplyr::select(kappa, p_t) |>
      dplyr::rename(kappa_est = kappa, pmem_est = p_t)
  )
} 
```

### Step 4: Look at the results of the toy example

Strange, when I call the resulting object from `runSimulation()` I get a tibble with some stats, but no results:

```{r print_res}
res
```

(PS: I was naughty and tried to get rid of the argument "fixed_objects" in the functions or to rename it. Alas, this is not allowed even if I have no use for it. Not a great design choice.)

Seems like something has change between the published tutorial paper (2020) and the current package version (11-2024), because when I run the `runSimulation()` function with the verbose option on, I get the following note:

```
Note: To extract Summarise() results use SimExtract(., what = 'summarise')
```

Ok? Let's try that:

```{r extract_res}
extract <- SimExtract(res, what = 'summarise')
str(extract[1:5])
```


A strange format... Oh, is it because I am outputing a list from Summarise?

```{r Summarise_df}
Summarise <- function(condition, results, fixed_objects) {
  data.frame(
    bias_kappa = mean(results$kappa_est - condition$kappa),
    bias_pmem = mean(results$pmem_est - condition$pmem),
    rmse_kappa = sqrt(mean((results$kappa_est - condition$kappa)^2)),
    rmse_pmem = sqrt(mean((results$pmem_est - condition$pmem)^2))
  )
}

res <- runSimulation(
  design = Design, replications = 100, generate = Generate,
  analyse = Analyse, summarise = Summarise, verbose = FALSE,
  parallel = TRUE, ncores = 10,
  save_results = TRUE, save_details = list(save_results_dirname = "output/SimDesign")
)

res
```

Yes, that was it. When I output a data.frame with a single row I get the results embeded. 
Wasn't this supposed to *not* rerun the simulation when I save the results? Hmm.

Ah, I just misunderstood the manual. The results are saved, but `runSimulation` runs anyway. I can use `reSummarise` to recompute the summaries from the saved results.

First, let's see what I can extract from the existing object. The bias and rmse single values are fine, but I wanted to see correlation across the design grid or perhaps plot the results. 

I should be able to use `SimExtract` to get the results from the `res` object:

```{r extract_res2}
SimExtract(res, what = 'results')
```

Nothing? 

Let's look at what is saved in the output directory:

```{r inspect_output}
list.files("output/SimDesign")
```

Ok, so I have a bunch of `.rds` files. I can load them and see what's inside:

```{r inspect_rds}
readRDS(list.files("output/SimDesign", full.names = TRUE)[1]) |> str()
```

Ok, that's what I wanted, I have the results for each replicatation stored in a data.frame `results`, and one `.rds` file for each row of the design grid.

Oh, it's actually a different command, `SimResults`:

```{r extract_res3}
str(SimResults(res)[1:3])
```

Although I have to wonder why this is in a list. Perhaps to save disk space. Although in [the tutorial](https://philchalmers.github.io/SimDesign/articles/SimDesign-intro.html) it just gives a data.frame.

*Note to self:* the reason why `SimExtract` didn't work and I needed to use `SimResults` is because I set the "save_results" argument to true. By default `store_results` is TRUE, meaning that the results are stored in the returned object and can be extracted. If `save_results` is set to TRUE, the results are saved to disk and not stored in the returned object.

Is there a command to aggregate the results, or do I need to write a function myself?

Before I go down that way, let me first replicate the example from the website:

```{r}
tutorial_design <- createDesign(
  sample_size = c(30, 60, 120, 240),
  distribution = c("norm", "chi")
)

tutorial_generate <- function(condition, fixed_objects) {
  N <- condition$sample_size
  dist <- condition$distribution
  if (dist == "norm") {
    dat <- rnorm(N, mean = 3)
  } else if (dist == "chi") {
    dat <- rchisq(N, df = 3)
  }
  dat
}

tutorial_analyse <- function(condition, dat, fixed_objects) {
  M0 <- mean(dat)
  M1 <- mean(dat, trim = .1)
  M2 <- mean(dat, trim = .2)
  med <- median(dat)

  ret <- c(mean_no_trim = M0, mean_trim.1 = M1, mean_trim.2 = M2, median = med)
  ret
}

tutorial_summarise <- function(condition, results, fixed_objects) {
  obs_bias <- bias(results, parameter = 3)
  obs_RMSE <- RMSE(results, parameter = 3)
  ret <- c(bias = obs_bias, RMSE = obs_RMSE, RE = RE(obs_RMSE))
  ret
}

tutorial_res <- runSimulation(tutorial_design,
  replications = 1000, generate = tutorial_generate,
  analyse = tutorial_analyse, summarise = tutorial_summarise,
  verbose = FALSE
)

tutorial_res
```

and the results are:

```{r}
SimResults(tutorial_res)
```

Ugh! So why are these aggregated but mine are not? Because these return a named vector and I return a data.frame? Let's try that:

```{r try_returning_vector}
Analyse <- function(condition, dat, fixed_objects) {
  suppressMessages(
    mixtur::fit_mixtur(dat, model = "2_component", unit = "radians") |>
      dplyr::select(kappa, p_t) |>
      dplyr::rename(kappa_est = kappa, pmem_est = p_t) |>
      unlist() # since the data.frame is just one row, this should give a named numeric vector
  )
}

Summarise <- function(condition, results, fixed_objects) {
  data.frame(
    bias_kappa = mean(results$kappa_est - condition$kappa),
    bias_pmem = mean(results$pmem_est - condition$pmem),
    rmse_kappa = sqrt(mean((results$kappa_est - condition$kappa)^2)),
    rmse_pmem = sqrt(mean((results$pmem_est - condition$pmem)^2))
  )
}

res <- runSimulation(
  design = Design, replications = 10, generate = Generate,
  analyse = Analyse, summarise = Summarise, verbose = FALSE,
  save_results = TRUE, save_details = list(save_results_dirname = "output/SimDesign")
)

SimResults(res)[1:3]
```

Hmm, no difference again. Can it be because I am using "save_results", instead of "store_results"? Let's try that:

```{r store_results_experiment}
res <- runSimulation(
  design = Design, replications = 10, generate = Generate,
  analyse = Analyse, summarise = Summarise, verbose = FALSE,
)

SimResults(res)
```


Ah, bingo! Ok, the output format of SimResults should not depend on options set in the `runSimulation` function. I [opened an issue on GitHub](https://github.com/philchalmers/SimDesign/issues/45).


## Minor things that annoy me

Should this section exist? Probably not. But there are a few minor things that just bug me for no good reason:

1. Not a fan of CamelCase function names, but I can live with that.
2. The `runSimulation` function at minimum takes the following arguments, and it annoys me that the numeric argument `replications` is in the middle of other arguments

```r
runSimulation(
  design = Design, 
  replications = 100, 
  generate = Generate,
  analyse = Analyse, 
  summarise = Summarise,
)
```

I know I can change the order of the arguments since they are named, but I prefer to keep the order of the arguments as they are in the documentation. I would have liked it more if replications was either the first argument, or if it followed the `summarise` argument.

3. The the computation functions require a "fixed_objects" argument even if they don't use it. The package backend should be handling this, not the user.
